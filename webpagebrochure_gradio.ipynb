{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "135da6e5-4378-4c56-856b-de427ff9943a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import ollama\n",
    "import time\n",
    "\n",
    "# Define headers for web scraping\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Class to fetch webpage content\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        self.soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = self.soup.title.string if self.soup.title else \"No title found\"\n",
    "\n",
    "        # Clean up text by removing unnecessary elements\n",
    "        if self.soup.body:\n",
    "            for irrelevant in self.soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = self.soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "\n",
    "        links = [link.get('href') for link in self.soup.find_all('a')]\n",
    "        self.links = [urljoin(self.url, link) for link in links if link]\n",
    "\n",
    "# Function to filter relevant links using Ollama\n",
    "def filter_relevant_links(links):\n",
    "    links_text = \"\\n\".join(links)\n",
    "    prompt = f\"\"\"\n",
    "    Here is a list of URLs extracted from a company's website:\n",
    "\n",
    "    {links_text}\n",
    "\n",
    "    Your task:\n",
    "    - Identify URLs that would be most relevant to include in a brochure about the company, such as About page, Careers/Job page, Services.\n",
    "    - Ignore links to terms of service, privacy, login pages, or external sites.\n",
    "    - Return only relevant URLs without any additional text or explanations.\n",
    "\n",
    "    Respond with the filtered list.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = None\n",
    "    while response is None:  # Keep retrying until we get a valid response\n",
    "        try:\n",
    "            response = ollama.chat(model=\"llama3.2\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        except Exception as e:\n",
    "            print(f\"Error encountered: {e}. Retrying in 5 seconds...\")\n",
    "            time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "\n",
    "    relevant_links = response['message']['content'].split(\"\\n\")\n",
    "    return [link.strip() for link in relevant_links if link.strip() and link.startswith(\"http\")]\n",
    "\n",
    "# Function to generate the brochure\n",
    "def generate_brochure_from_contents(scraped_text):\n",
    "    prompt = f\"\"\"\n",
    "    Create a brochure based on the following website content:\n",
    "\n",
    "    {scraped_text}\n",
    "\n",
    "    Your task is to generate a professional brochure without any picture that highlights key information about the company, such as:\n",
    "    - Services\n",
    "    - Products\n",
    "    - Values\n",
    "    - Mission\n",
    "    - Impact\n",
    "    - Webpage\n",
    "    - Contact e-mail\n",
    "\n",
    "    The brochure should be concise and informative. Do not include placeholders like '[Cover Page]', '[Insert Twitter Handle]', or similar.\n",
    "    Ensure all content is strictly from the provided context.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"You are a helpful assistant tasked with generating a professional brochure from a company's web content. Follow these rules:\n",
    "    1. Focus only on the company's relevant information (services, products, values, mission).\n",
    "    2. Ignore external links, placeholders, or unrelated content.\n",
    "    3. Do not add unnecessary formatting (e.g., page numbers, cover page, or picture placeholders).\n",
    "    \"\"\"\n",
    "\n",
    "    response = None\n",
    "    while response is None:  # Keep retrying until we get a valid response\n",
    "        try:\n",
    "            response = ollama.chat(model=\"llama3.2\", messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ])\n",
    "        except Exception as e:\n",
    "            print(f\"Error encountered: {e}. Retrying in 5 seconds...\")\n",
    "            time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "\n",
    "    return response['message']['content']\n",
    "\n",
    "# Convert to markdown format\n",
    "def convert_to_markdown(content):\n",
    "    markdown = \"\"\n",
    "    lines = content.split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith(\"**\"):\n",
    "            markdown += f\"## {line.strip('**')}\\n\"\n",
    "        elif line.startswith(\"*\"):\n",
    "            markdown += f\"- {line[2:]}\\n\"\n",
    "        else:\n",
    "            markdown += f\"{line}\\n\"\n",
    "    \n",
    "    return markdown\n",
    "\n",
    "# Define the function to be used in Gradio\n",
    "def process_url(url):\n",
    "    if not url.startswith(\"http\"):\n",
    "        url = \"https://\" + url  # Ensure URL starts with \"http\" or \"https\"\n",
    "\n",
    "    # Fetch the website\n",
    "    web = Website(url)\n",
    "\n",
    "    # Reset the variables to avoid stale data\n",
    "    filter_links = []  \n",
    "    web_contents = []  \n",
    "\n",
    "    # Step 1: Get filtered links\n",
    "    filter_links = filter_relevant_links(web.links)\n",
    "    \n",
    "    if not filter_links:  # If no relevant links are found, return an error message\n",
    "        return \"No relevant links found. Try a different website.\"\n",
    "\n",
    "    # Step 2: Extract text from each relevant link\n",
    "    for link in filter_links:\n",
    "        web_page = Website(link)  \n",
    "        \n",
    "        # Filter out lines with at most 3 words\n",
    "        filtered_text = \"\\n\".join(line for line in web_page.text.split(\"\\n\") if len(line.split()) > 3)\n",
    "        \n",
    "        # Store extracted content\n",
    "        web_contents.append((web_page.title, link, filtered_text))\n",
    "\n",
    "    # Step 3: Prepare text for Ollama\n",
    "    scraped_text = \"\\n\\n\".join([f\"Title: {title}\\nLink: {link}\\nContent: {text}\" for title, link, text in web_contents])\n",
    "\n",
    "    # Step 4: Generate brochure\n",
    "    brochure = generate_brochure_from_contents(scraped_text)\n",
    "\n",
    "    # Convert to Markdown\n",
    "    markdown_brochure = convert_to_markdown(brochure)\n",
    "\n",
    "    return markdown_brochure\n",
    "\n",
    "# Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_url,\n",
    "    inputs=gr.Textbox(label=\"Enter Website URL\"),\n",
    "    outputs=gr.Markdown(label=\"Generated Brochure\"),\n",
    "    title=\"Company Brochure Generator\",\n",
    "    description=\"Enter a company website URL to generate a markdown-formatted brochure.\",\n",
    ")\n",
    "\n",
    "# Launch Gradio App\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebfc7ce-3387-4d74-a9dd-4a0668ccc7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
